{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"./images/EAN.jpg\" style=\"width:1200px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"./images/0_intro_ml.jpg\" style=\"width:1200px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lecture 5: Model Evaluation and Improvement\n",
    "*Resampling methods, Grid Search, Evaluation Metrics and Scoring*\n",
    "\n",
    "\n",
    "## Instructors:\n",
    "\n",
    ">Leonardo A. Espinosa, PhD. Instructor.\n",
    "(*email*: leonardo.espinosaleal@arcada.fi)\n",
    "\n",
    "> Ruben D. Acosta, MSc. Instructor.\n",
    "(*email*:  rdacostav@universidadean.edu.co)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Learning goals for today\n",
    "* Understand the different methods for validating data.\n",
    "* Being able to understand the different metrics and its peculiarities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "39576c63-298e-4a6d-ac14-aba4e1c4d006"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1\\. <a href=\"#/3/1\">Resampling methods</a>\n",
    "\n",
    "2\\. <a href=\"#/14/1\">Grid Search</a>:\n",
    "   * <a href=\"#/15/1\">Simple</a>.\n",
    "   * <a href=\"#/24/1\">With cross-validation</a>.\n",
    " \n",
    "3\\. <a href=\"#/41/1\">Evaluation Metrics and Scoring</a>\n",
    "   * <a href=\"#/42/1\">Metrics for Binary Classification</a>.\n",
    "   * <a href=\"#/78/1\">Metrics for Multiclass Classification</a>.\n",
    "   * <a href=\"#/83/1\">Using Evaluation Metrics in Model Selection</a>\n",
    "   \n",
    "4\\. <a href=\"#/88/1\">Conclusions</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/data_squezz.jpg\" style=\"width: 1450px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Resampling methods\n",
    "\n",
    "* Drawing samples from a training set and reffiting the model of interest on each sample. \n",
    "* A way to obtain additional information about the fitted model.\n",
    "\n",
    ">Model assessment: Evaluating the model performance.\n",
    "\n",
    ">Model selection: Selecting the proper level of flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a089a6f8-158b-483a-8f20-71af2d3f96d7"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cross-Validation\n",
    "Cross-validation is primarily a way of measuring the predictive performance of a statistical model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "99fb9fd7-4894-4436-a3a4-d4c8cc4d4716"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-Fold cross-validation\n",
    "<center><img src=\"./images/04-K-fold_cv.png\" style=\"width: 750px;\"/></center>\n",
    "\n",
    "* Avoid *random* bias during selection of train and test data.\n",
    "* How sensitive is our model to the selection of the training set.\n",
    "* Computational cost is *k*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1a2123db-9495-46fd-8b45-2793922819d4"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Stratified k-fold cross validation\n",
    "<center><img src=\"./images/04-SK-fold_cv.png\" alt=\"Drawing\" style=\"width: 780px;\"/></center>\n",
    "\n",
    "* Keeps the proportion between classes in each fold as they are in the whole dataset.\n",
    "* Good strategy with Imbalanced datasets (but use other strategies if proportion is more than 9 to 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "865aabe8-fa7a-42c6-821e-284e7d1eac20"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Leave-one-out cross-validation\n",
    "<center><img src=\"./images/04-LOO_cv.png\" alt=\"Drawing\" style=\"width: 750px;\"/></center>\n",
    "\n",
    "* Good results in small datasets.\n",
    "* Warning: Time consuming for large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "4c0046b6-ffb7-4e8a-8b52-74d9acb5bb76"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Shuffle-split cross-validation\n",
    "<center><img src=\"./images/04-Random_cv.png\" alt=\"Drawing\" style=\"width: 750px;\"/></center>\n",
    "* Good strategy with large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bootstrapping\n",
    "\n",
    "Quantify the uncertainty associated with a given estimator or statistical learning method.\n",
    "\n",
    "* It is *easy* to derive estimates for standard errors and confidence intervals for complex estimators.\n",
    "* It is not proven to work on finite samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/bootstrap.png\" alt=\"Drawing\" style=\"width: 750px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"./images/00_questions.jpg\" style=\"width:1200px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "7832eee9-dc9d-44f6-8fce-46ccbe3fa960"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Grid Search\n",
    "\n",
    "Improve the models' generalization performance by tuning its parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "20b08b8f-ef96-420c-90b7-49062d3b0f45"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Grid Search\n",
    "\n",
    "Using *for* loops over the parameters of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mglearn\n",
    "from IPython.display import display\n",
    "\n",
    "from matplotlib import rc\n",
    "font = {'family' : 'monospace', 'weight' : 'bold', 'size'   : 25}\n",
    "rc('font', **font) \n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "plt.rcParams['lines.linewidth'] = 5.0\n",
    "plt.rcParams['lines.markersize'] = 15.0\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "418730a6-6d22-4878-ae29-6d4ef1572ae2"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
    "print(\"Size of training set: {} size of test set: {}\".format(X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "a1887145-230d-4452-b425-7c659490b3ef"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# naive grid search implementation\n",
    "best_score = 0\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        # for each combination of parameters, train an SVC\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        # evaluate the SVC on the test set\n",
    "        score = svm.score(X_test, y_test)\n",
    "        # if we got a better score, store the score and parameters\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}\n",
    "\n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "bcb7b795-c864-424e-9be6-684e5b2a15ff"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overfiting *parameters* and the Validation Set\n",
    "\n",
    "* We have tried different parameters and select the best ones on the *test set*.\n",
    "* Test data should not be use to assess how good is the model.\n",
    "* A new independent data set is necessary $\\to$ Validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "e0b9018c-8184-4eb9-ba8b-01bf3225e168"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/04-TVT_sets.png\" alt=\"Drawing\" style=\"width:1000px\" align=\"middle\"/></center>\n",
    "\n",
    "* **Training set**: build the model.\n",
    "* **Validation set**: select the parameters of the model.\n",
    "* **Test set**: evaluate the performance of the selected parameters.\n",
    "\n",
    "After selecting the best parameters using the validation set, we can rebuild a model using the parameter settings we found, but now training on both the training data and the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "9bd41e05-91ea-4bce-8884-cf240321fa7d"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# split data into train+validation set and test set\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
    "\n",
    "# split train+validation set into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_trainval, y_trainval, random_state=1)\n",
    "\n",
    "print(\"Size of training set: {} size of validation set: {} size of test set:\" \n",
    "      \" {}\\n\".format(X_train.shape[0], X_valid.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "9c430ab5-7187-41af-b53b-ef9faeda2d13"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        # for each combination of parameters, train an SVC\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        # evaluate the SVC on the test set\n",
    "        score = svm.score(X_valid, y_valid)\n",
    "        # if we got a better score, store the score and parameters\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "3f6ff5ee-5ed5-4e9a-9e55-c8aa59829485"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# rebuild a model on the combined training and validation set,\n",
    "# and evaluate it on the test set\n",
    "svm = SVC(**best_parameters)\n",
    "svm.fit(X_trainval, y_trainval)\n",
    "test_score = svm.score(X_test, y_test)\n",
    "print(\"Best score on validation set: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: \", best_parameters)\n",
    "print(\"Test set score with best parameters: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "b2a92366-f696-4e15-a744-b45ab7986ff3"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grid Search with Cross-Validation\n",
    "\n",
    "* For a better estimate of the generalization performance. \n",
    "\n",
    "* Instead of using a single split into a training and a validation set, we can use cross-validation to evaluate the performance of each parameter combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "52e28ee0-6d22-4de4-b8cb-489b3266bd58"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        # for each combination of parameters,\n",
    "        # train an SVC\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        # perform cross-validation\n",
    "        scores = cross_val_score(svm, X_trainval, y_trainval, cv=5)\n",
    "        # compute mean cross-validation accuracy\n",
    "        score = np.mean(scores)\n",
    "        \n",
    "        # if we got a better score, store the score and parameters\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rebuild a model on the combined training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "svm = SVC(**best_parameters)\n",
    "svm.fit(X_trainval, y_trainval)\n",
    "\n",
    "test_score = svm.score(X_test, y_test)\n",
    "print(\"Best score on validation set: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: \", best_parameters)\n",
    "print(\"Test set score with best parameters: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "5eef5b52-3f7b-4597-ad9e-493ea9fb6246"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10,120],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test, y_test)))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\\n\".format(grid_search.best_score_))\n",
    "print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c11eff5e-84d0-488d-9c42-c55ed2c3a046"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**best$\\underline{}$score$\\underline{}$** $\\to$ The  mean accuracy over the different splits for the parameters setting. On the training set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0005f353-4639-4554-905c-8f25c310c224"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Analyzing the results (cv$\\underline{}$results$\\underline{}$)\n",
    "\n",
    "We can inspect the results of the cross-validated grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "7ed9ca3a-caa0-4617-a62d-a4967e21302e"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# convert to DataFrame\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "# show the first 5 rows\n",
    "display(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "5933f028-0f50-49f3-84dd-381ffa720c55"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "scores = np.array(results.mean_test_score).reshape(6, 6)\n",
    "# plot the mean cross-validation scores\n",
    "mglearn.tools.heatmap(scores, xlabel='gamma', xticklabels=param_grid['gamma'],\n",
    "ylabel='C', yticklabels=param_grid['C'], cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "8dc489fd-3b8f-43ac-8e47-226561ee1f8b"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "param_grid_linear = {'C': np.linspace(1, 2, 6),\n",
    "                     'gamma': np.linspace(1, 2, 6)}\n",
    "\n",
    "param_grid_one_log = {'C': np.linspace(1, 2, 6),\n",
    "                      'gamma': np.logspace(-3, 2, 6)}\n",
    "\n",
    "param_grid_range = {'C': np.logspace(-3, 2, 6),\n",
    "                    'gamma': np.logspace(-7, -2, 6)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "458175ff-9c19-4400-b5b1-46d05b2627c8"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "font = {'family' : 'monospace', 'weight' : 'bold', 'size'   : 18}\n",
    "rc('font', **font) \n",
    "plt.rcParams['figure.figsize'] = [35, 10]\n",
    "\n",
    "def plot_params():\n",
    "    fig, axes = plt.subplots(1, 3)\n",
    "    for param_grid, ax in zip([param_grid_linear, param_grid_one_log,\n",
    "                               param_grid_range], axes):\n",
    "        grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        scores = grid_search.cv_results_['mean_test_score'].reshape(6, 6)\n",
    "\n",
    "        # plot the mean cross-validation scores\n",
    "        scores_image = mglearn.tools.heatmap(\n",
    "                       scores, xlabel='gamma', ylabel='C', xticklabels=param_grid['gamma'],\n",
    "                       yticklabels=param_grid['C'], cmap=\"viridis\", ax=ax)\n",
    "    plt.colorbar(scores_image, ax=axes.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "font = {'family' : 'monospace', 'weight' : 'bold', 'size'   : 25}\n",
    "rc('font', **font) \n",
    "plt.rcParams['figure.figsize'] = [25, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "e08fda87-8647-4459-a809-abbdcf18ebfe"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Search over spaces (not grids)\n",
    "\n",
    "* In general is not a good idea.\n",
    "* But, in some cases is possible to try *all possible* combinations of *all paramenters*.\n",
    "* Pass to GridSearch a **list of dictionaries**. Each dictionary an independent grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "00d38547-0a6c-4c96-ac2f-aed0524ef66c"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# We test the SVC classifier with two type of kernels.\n",
    "param_grid = [{'kernel': ['rbf'],\n",
    "               'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "               'gamma': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "              {'kernel': ['linear'],\n",
    "               'C': [0.001, 0.01, 0.1, 1, 10, 100]}]\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "3c6e0171-18a6-4adb-a81c-3dd1872e877a"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "# we display the transposed table so that it better fits on the page:\n",
    "display(results.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "f03ddf67-607d-43d5-ba04-be2e6a0f134c"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Extra info\n",
    "\n",
    "\n",
    "* You can Parallelize the cross-validation and grid search by passing the option `n_jobs=-1`\n",
    "\n",
    "* GridSearchCV uses stratified *k*-fold cross-validation by default. But you can change it by passing a different\n",
    "instruction to the **cv** variable. eg. \n",
    "\n",
    "    ```from sklearn.model_selection import LeaveOneOut\n",
    "  loo = LeaveOneOut()\n",
    "  grid_search = GridSearchCV(SVC(), param_grid, cv=loo)```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"./images/00_questions.jpg\" style=\"width:1200px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"./images/00_hands-on.jpg\" style=\"width:1200px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's test gridsearch!\n",
    "\n",
    "Here we run a gridsearch model for the dataset of your project:\n",
    "\n",
    "* Create a grid of parameters searching for two hyperparamenters.\n",
    "* Evaluate how the model improves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "6f63fa54-d56f-434f-943f-be2a6f0e3d05"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluation Metrics and Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"./images/metrics.png\" style=\"width:1200px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "2564c16a-8437-4ca7-a63d-82789db10af7"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Default evaluation metrics in scikit-learn\n",
    "* for classification: accuracy\n",
    "* for regression: $R^2$\n",
    "\n",
    "$R^2$ for regression is the usual one. It is a statistical measure of how close the data are to the fitted regression line. It is also known as the coefficient of determination, or the coefficient of multiple determination for multiple regression. However you can also use *Mean Absolute Error* or *Mean Squared Error* but the cases are limited. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*When selecting a metric, you should always have the end goal of the machine learning application in mind.*\n",
    "\n",
    "> business metric $\\to$ business impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "43e9b8d9-0f53-40f3-b8d9-c5b60fad5133"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**be careful with imbalanced datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "c4ec721c-2942-42d9-a1e4-2c621eb12fb9"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "y = digits.target == 9\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_majority = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "pred_most_frequent = dummy_majority.predict(X_test)\n",
    "print(\"Unique predicted labels: {}\".format(np.unique(pred_most_frequent)))\n",
    "print(\"Test score: {:.2f}\".format(dummy_majority.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=2).fit(X_train, y_train)\n",
    "pred_tree = tree.predict(X_test)\n",
    "print(\"Test score: {:.2f}\".format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "dummy = DummyClassifier().fit(X_train, y_train)\n",
    "pred_dummy = dummy.predict(X_test)\n",
    "print(\"dummy score: {:.2f}\".format(dummy.score(X_test, y_test)))\n",
    "\n",
    "logreg = LogisticRegression(C=0.01).fit(X_train, y_train)\n",
    "pred_logreg = logreg.predict(X_test)\n",
    "print(\"logreg score: {:.2f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Confusion matrices\n",
    "\n",
    "* rows $\\to$ true classes\n",
    "* columns $\\to$ predicted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(y_test, pred_logreg)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_confusion_matrix_illustration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "font = {'family' : 'monospace', 'weight' : 'bold', 'size'   : 25}\n",
    "rc('font', **font) \n",
    "plt.rcParams['figure.figsize'] = [25, 10]\n",
    "mglearn.plots.plot_binary_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Most frequent class:\")\n",
    "print(confusion_matrix(y_test,pred_most_frequent))\n",
    "print(\"\\nDummy model:\")\n",
    "print(confusion_matrix(y_test,pred_dummy))\n",
    "print(\"\\nDecision tree:\")\n",
    "print(confusion_matrix(y_test, pred_tree))\n",
    "print(\"\\nLogistic Regression\")\n",
    "print(confusion_matrix(y_test,pred_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Accuracy: $\\frac{TP+TN}{TP + TN + FP + FN}$\n",
    "\n",
    "* Precision: $\\frac{TP}{TP + FP}$ (fraction of relevant instances among the retrieved instances)\n",
    "\n",
    "* Recall:    $\\frac{TP}{TP + FN}$  (fraction of the total amount of relevant instances that were actually retrieved) \n",
    "\n",
    "* f-score:  $2\\cdot \\frac{precision\\cdot recall}{precision+recall}$ (harmonic mean of precision and recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/precisionrecall.png\" style=\"width: 1000px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/cm1.png\" style=\"width: 1000px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/cm2.png\" style=\"width: 800px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/cm1.png\" style=\"width: 1000px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"f1 score most frequent: {:.2f}\".format(f1_score(y_test, pred_most_frequent)))\n",
    "print(\"f1 score dummy: {:.2f}\".format(f1_score(y_test, pred_dummy)))\n",
    "print(\"f1 score tree: {:.2f}\".format(f1_score(y_test, pred_tree)))\n",
    "print(\"f1 score logistic regression: {:.2f}\".format(f1_score(y_test, pred_logreg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pred_most_frequent,target_names=[\"not nine\", \"nine\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_dummy,target_names=[\"not nine\", \"nine\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_logreg,target_names=[\"not nine\", \"nine\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Taking uncertainty into account\n",
    "\n",
    "Most of classifiers provide a:\n",
    "\n",
    "* decision_function\n",
    "* predict_proba\n",
    "\n",
    "You can modify the output by tuning a threshold.\n",
    "\n",
    ">If you do set a threshold, don't use the test set. As with any other parameter, setting a decision threshold on the test set is likely to yield overly optimistic results. Use a validation set or cross-validation instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from mglearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(n_samples=(400, 50), centers=2, cluster_std=[7.0, 2],random_state=22)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "svc = SVC(gamma=.1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "font = {'family' : 'monospace', 'weight' : 'bold', 'size'   : 12}\n",
    "rc('font', **font) \n",
    "plt.rcParams['figure.figsize'] = [30, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_decision_threshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, svc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_lower_threshold = svc.decision_function(X_test) > -.8\n",
    "print(classification_report(y_test, y_pred_lower_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Precision-recall curves and ROC curves\n",
    "\n",
    "Adjust the trade-off of precision and recall for a given classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "font = {'family' : 'monospace', 'weight' : 'bold', 'size'   : 25}\n",
    "rc('font', **font) \n",
    "plt.rcParams['figure.figsize'] = [25, 15]\n",
    "plt.rcParams['lines.markersize'] = 20\n",
    "#plt.rcParams.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X, y = make_blobs(n_samples=(4000, 500), centers=2, cluster_std=[7.0, 2],\n",
    "random_state=22)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "svc = SVC(gamma=.05).fit(X_train, y_train)\n",
    "precision, recall, thresholds = precision_recall_curve(\n",
    "y_test, svc.decision_function(X_test))\n",
    "# find threshold closest to zero\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0, max_features=2)\n",
    "rf.fit(X_train, y_train)\n",
    "# RandomForestClassifier has predict_proba, but not decision_function\n",
    "precision_rf, recall_rf, thresholds_rf = precision_recall_curve(\n",
    "y_test, rf.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_pre_rec():\n",
    "    plt.plot(precision, recall, label=\"svc\")\n",
    "    plt.plot(precision[close_zero], recall[close_zero], 'o',\n",
    "             label=\"threshold zero svc\", fillstyle=\"none\", c='k', mew=2)\n",
    "    plt.plot(precision_rf, recall_rf, label=\"rf\")\n",
    "    close_default_rf = np.argmin(np.abs(thresholds_rf - 0.5))\n",
    "    plt.plot(precision_rf[close_default_rf], recall_rf[close_default_rf], '^', c='k', \n",
    "             label=\"threshold 0.5 rf\", fillstyle=\"none\", mew=2)\n",
    "    plt.xlabel(\"Precision\")\n",
    "    plt.ylabel(\"Recall\")\n",
    "    plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_pre_rec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "ap_rf = average_precision_score(y_test, rf.predict_proba(X_test)[:, 1])\n",
    "ap_svc = average_precision_score(y_test, svc.decision_function(X_test))\n",
    "print(\"Average precision of random forest: {:.3f}\".format(ap_rf))\n",
    "print(\"Average precision of svc: {:.3f}\".format(ap_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Receiver operating characteristics (ROC) and AUC\n",
    "* false positive rate (FPR) against the true positive rate (TPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"./images/ROC_space.png\" style=\"width: 850px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def plot_roc_curve():\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, svc.decision_function(X_test))\n",
    "    fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, rf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "    close_zero = np.argmin(np.abs(thresholds))\n",
    "\n",
    "    plt.plot(fpr, tpr, label=\"ROC Curve SVC\")\n",
    "    plt.plot(fpr_rf, tpr_rf, label=\"ROC Curve RF\")\n",
    "    plt.xlabel(\"FPR\")\n",
    "    plt.ylabel(\"TPR (recall)\")\n",
    "    plt.plot(fpr[close_zero], tpr[close_zero], 'o', \n",
    "    label=\"threshold zero SVC\", fillstyle=\"none\", c='k', mew=2)\n",
    "    close_default_rf = np.argmin(np.abs(thresholds_rf - 0.5))\n",
    "    plt.plot(fpr_rf[close_default_rf], tpr[close_default_rf], '^',\n",
    "    label=\"threshold 0.5 RF\", fillstyle=\"none\", c='k', mew=2)\n",
    "    plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_roc_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "rf_auc = roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1])\n",
    "svc_auc = roc_auc_score(y_test, svc.decision_function(X_test))\n",
    "print(\"AUC for Random Forest: {:.3f}\".format(rf_auc))\n",
    "print(\"AUC for SVC: {:.3f}\".format(svc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*AUC is a better metric for imbalanced classification problems than accuracy.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Metrics for Multiclass Classification\n",
    "\n",
    "Same than binary classification metrics, but averaged over all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "digits.data, digits.target, random_state=0)\n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "pred = lr.predict(X_test)\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion_matrix(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_conf_matrix():\n",
    "    scores_image = mglearn.tools.heatmap(\n",
    "    confusion_matrix(y_test, pred), xlabel='Predicted label',\n",
    "    ylabel='True label', xticklabels=digits.target_names,\n",
    "    yticklabels=digits.target_names, cmap=plt.cm.gray_r, fmt=\"%d\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_conf_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using Evaluation Metrics in Model Selection\n",
    "\n",
    "How to include your metric in your model selection using GridSearchCV or cross_val_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target == 9, random_state=0)\n",
    "# we provide a somewhat bad grid to illustrate the point:\n",
    "param_grid = {'gamma': [0.0001, 0.01, 0.1, 1, 10]}\n",
    "# using the default scoring of accuracy:\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Grid-Search with accuracy\")\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best cross-validation score (accuracy)): {:.3f}\".format(grid.best_score_))\n",
    "print(\"Test set AUC: {:.3f}\".format(\n",
    "roc_auc_score(y_test, grid.decision_function(X_test))))\n",
    "print(\"Test set accuracy: {:.3f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# using AUC scoring instead:\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, scoring=\"roc_auc\")\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"\\nGrid-Search with AUC\")\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best cross-validation score (AUC): {:.3f}\".format(grid.best_score_))\n",
    "print(\"Test set AUC: {:.3f}\".format(\n",
    "roc_auc_score(y_test, grid.decision_function(X_test))))\n",
    "print(\"Test set accuracy: {:.3f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.scorer import SCORERS\n",
    "print(\"Available scorers:\\n{}\".format(sorted(SCORERS.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"./images/00_questions.jpg\" style=\"width:1200px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"./images/00_hands-on.jpg\" style=\"width:1200px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise\n",
    "\n",
    "Here we are going to model the *identification glass dataset*\n",
    "https://archive.ics.uci.edu/ml/datasets/glass+identification\n",
    "\n",
    "1. Explore the Dataset\n",
    "2. Fit a same model using k-fold cross-validation and RepeatedStratifiedKFold.\n",
    "3. Compare different scoring methods: accuracy and auc.\n",
    "4. What is the final result? Improves?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusions\n",
    "\n",
    "* Cross-validation or the use of a test set allow us to evaluate a machine learning model as it will perform in the future.\n",
    "* Make sure that the metric you choose to evaluate and select a model for is a good stand-in for what the model will actually be used for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"./images/00_thats_all.jpg\" style=\"width:1200px\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_metadata": {
   "author": "Leonardo Espinosa",
   "title": "MLPP: Supervised Learning"
  },
  "livereveal": {
   "overlay": "<div class='myheader'><h2 class='headertekst'>Elementos de Machine Learning y Deep Learning. Universidad EAN </h2><h3 ><a href='#/21/1'>(index)</a></h3></div>",
   "progress": true,
   "scroll": true,
   "theme": "serif",
   "transition": "simple"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
